{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U pandas matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import h5py\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "from pathlib import Path\n",
    "from itertools import product\n",
    "\n",
    "import sklearn.model_selection\n",
    "import tensorflow as tf\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.get_lock().locks = []\n",
    "\n",
    "from IPython.display import Image, display, HTML, Math, Latex\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import altair as alt\n",
    "import dataframe_image as dfi\n",
    "\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.offline as ply\n",
    "import plotly.graph_objs as plygo\n",
    "import cufflinks as cf\n",
    "\n",
    "plotly.io.orca.config.executable = '/home/kiran/.local/bin/orca'\n",
    "ply.init_notebook_mode(connected=False)\n",
    "cf.set_config_file(offline=True, world_readable=False, theme='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.hsi_dataset import HSIDataset\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {'Suburban': '/storage/kiran/data/suburban/20170820_Urban_Ref_Reg_Subset.tif',\n",
    "            'Urban': '/storage/kiran/data/urban/20170820_Urban2_INT_Final.tif',\n",
    "            'Forest': '/storage/kiran/data/forest/20170820_Forest_Final_INT.tif'        \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect results from H5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "h5_files = list(Path('/storage/kiran/results/data/').glob('*.h5'))\n",
    "metrics = []\n",
    "confusion_matrices = {}\n",
    "l = widgets.Label(value=\"Not started...\")\n",
    "display(l)\n",
    "for path in tqdm(h5_files[:]):    \n",
    "    h5_file = h5py.File(path, 'r')    \n",
    "    attrs = dict(h5_file.attrs.items())\n",
    "    l.value = f\"{path}\"    \n",
    "    predicted = h5_file['predictions'][()]\n",
    "    targets = h5_file['targets'][()]\n",
    "    \n",
    "    dataset_name = attrs['dataset_name']\n",
    "    input_type = attrs['input_type']\n",
    "    compression_class = attrs['compression_class']\n",
    "\n",
    "    n_components = int(attrs['n_components'])\n",
    "    compression_rate = int(attrs['compression_rate']*100)\n",
    "    reconstruction_loss = attrs['reconstruction_loss']\n",
    "    \n",
    "    execution_times = json.loads(attrs['execution_times'])\n",
    "    \n",
    "    l.value = f\"{path} -- {dataset_name} ; {attrs['compression_class']} ; {attrs['input_type']} ; {attrs['compression_rate']}\"\n",
    "    \n",
    "    dataset_file = datasets[dataset_name]\n",
    "    dataset = HSIDataset(dataset_file, dataset_name)\n",
    "    labels, _  = dataset.trainingset\n",
    "    \n",
    "    labels.pop('undefined',None)    \n",
    "\n",
    "    # -------------------------------------------------------------------------------- #    \n",
    "    # Record for categories weighted average \n",
    "    precision, recall, fbeta_score, support = precision_recall_fscore_support(y_true=targets, y_pred=predicted, labels=list(labels.values()), average='weighted')    \n",
    "    record = [dataset_name, input_type, compression_class,\n",
    "              compression_rate,  n_components, \n",
    "              \"average_weighted\", precision, recall, fbeta_score, support, \n",
    "              reconstruction_loss, execution_times\n",
    "             ]\n",
    "    metrics.append(record)\n",
    "        \n",
    "    # -------------------------------------------------------------------------------- #\n",
    "    # Record for each category\n",
    "    precision, recall, fbeta_score, support = precision_recall_fscore_support(y_true=targets, y_pred=predicted, labels=list(labels.values()), average=None)    \n",
    "    for idx, label in enumerate(labels.keys()):\n",
    "        record = [dataset_name, input_type, compression_class, \n",
    "                  compression_rate, n_components, \n",
    "                  label, precision[idx], recall[idx], fbeta_score[idx], support[idx], \n",
    "                  reconstruction_loss, execution_times\n",
    "                 ]\n",
    "        metrics.append(record)\n",
    "        \n",
    "    # -------------------------------------------------------------------------------- #\n",
    "    # Confusion Matrices\n",
    "    confusion_matrix = sklearn.metrics.confusion_matrix(y_true=targets, y_pred=predicted, labels=list(labels.values()))            \n",
    "    confusion_matrix = pd.DataFrame(confusion_matrix, columns=list(labels.keys()))\n",
    "    confusion_matrix.index = confusion_matrix.columns\n",
    "    confusion_matrix.apply(func=lambda item: item/item.sum(), axis=1)\n",
    "    confusion_matrix = confusion_matrix.div(confusion_matrix.sum(axis=1), axis=0)    \n",
    "    confusion_matrices[(dataset_name, input_type, compression_class, int(compression_rate), )] = confusion_matrix\n",
    "\n",
    "del h5_files\n",
    "\n",
    "df_metrics = pd.DataFrame(metrics, columns=['dataset_name','input_type', 'compression_class',\n",
    "                                            'compression_rate', 'n_components', \n",
    "                                            'label','precision', 'recall', 'f1', 'support', \n",
    "                                            'reconstruction_loss', 'execution_times'\n",
    "                                           ]\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write\n",
    "# df_metrics.to_pickle('/storage/kiran/results/df_metrics.pickle')\n",
    "# import pickle; pickle.dump( confusion_matrices, open( \"/storage/kiran/results/confusion_matrices.pickle\", \"wb\" ) )\n",
    "\n",
    "# Read\n",
    "df_metrics = pd.read_pickle('/storage/kiran/results/df_metrics.pickle')\n",
    "import pickle; confusion_matrices = pickle.load(open( \"/storage/kiran/results/confusion_matrices.pickle\", \"rb\" ) )\n",
    "\n",
    "display(confusion_matrices[('Forest', 'HSI', 'AE', 96)])\n",
    "display(df_metrics.groupby(['dataset_name','input_type','compression_class','label', 'compression_rate','compression_rate']).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_metrics = df_metrics.sort_values(['dataset_name','compression_class','label', 'compression_rate'])\n",
    "df_metrics.reset_index(inplace=True, drop=True)\n",
    "\n",
    "datasets = ['Suburban', 'Urban','Forest']\n",
    "input_types = ['HSI', 'HSI_SG']\n",
    "compression_classes = [\"RGB\",\"PCA\",\"KPCA\",\"ICA\", \"AE\",\"DAE\"]\n",
    "\n",
    "categories = sorted(df_metrics.label.unique().tolist())\n",
    "\n",
    "print(df_metrics.shape)\n",
    "display(df_metrics.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_metrics[(df_metrics.label=='average_weighted')&(df_metrics.input_type!='HSI_SG')]\n",
    "cr=0\n",
    "df.loc[df.input_type=='RGB', 'compression_class'] = 'RGB'\n",
    "df.loc[df.input_type=='RGB', 'compression_rate'] = cr\n",
    "df.loc[df.input_type=='RGB', 'input_type'] = 'HSI'\n",
    "df.loc[df.compression_class=='NA', 'compression_class'] = 'HSI'\n",
    "df.rename({'f1':'f1-score'}, axis=1, inplace=True)\n",
    "\n",
    "df = df[((df.compression_rate>0)&(df.compression_rate<97))|(df.input_type>='RGB')|(df.compression_class>='HSI')]\n",
    "\n",
    "del df['support']\n",
    "del df['reconstruction_loss']\n",
    "del df['execution_times']\n",
    "del df['n_components']\n",
    "del df['input_type']\n",
    "del df['precision']\n",
    "del df['recall']\n",
    "\n",
    "df = df.groupby(['dataset_name','compression_class','compression_rate','label']).max().reset_index()\n",
    "\n",
    "del df['dataset_name']\n",
    "del df['compression_rate']\n",
    "del df['label']\n",
    "\n",
    "\n",
    "df = df.melt(id_vars=['compression_class']).reset_index(drop=True)\n",
    "\n",
    "fig = px.box(data_frame=df, \n",
    "             x='variable', \n",
    "             y='value', \n",
    "             color='compression_class', \n",
    "             template='plotly_white',\n",
    "             points='suspectedoutliers',\n",
    "             range_y=[0.8,1],\n",
    "             boxmode='group',\n",
    "             notched=False,\n",
    "             category_orders={\"compression_class\": [\"RGB\",\"HSI\",\"PCA\",\"KPCA\",\"ICA\",\"AE\",\"DAE\"]},\n",
    "            )\n",
    "\n",
    "\n",
    "# fig.for_each_annotation(lambda a: a.update(text=a.text.replace(\"input_type=\", \"\")))\n",
    "# fig.for_each_annotation(lambda a: a.update(text=a.text.replace(\"dataset_name=\", \"\")))\n",
    "# fig.for_each_annotation(lambda a: a.update(text=a.text.replace(\"timer\", \"\")))\n",
    "# fig.for_each_trace(lambda t: t.update(name=t.name.replace(\"compression_\", \"\")))\n",
    "fig.update_layout(legend_title=\"\", font=dict(size=30, color=\"Black\", family='Times New Roman'))\n",
    "fig.update_yaxes(title_standoff=0, title_font=dict(size=30, family='Times New Roman'))\n",
    "fig.update_xaxes(title_standoff=0, title_font=dict(size=30, family='Times New Roman'))\n",
    "\n",
    "fig.layout.xaxis.title.text = \"\"\n",
    "fig.layout.yaxis.title.text  = \"\"\n",
    "# fig.layout.update(showlegend=False)\n",
    "\n",
    "fig.update_layout(boxgroupgap=0.2, boxgap=0.2)\n",
    "\n",
    "# fig.update_layout(shapes=[dict(type= 'line',\n",
    "#                                yref= 'paper', y0= 0, y1= 0.9,\n",
    "#                                xref= 'x', x0= 0.5, x1= 0.5\n",
    "#                               ),\n",
    "#                           dict(type= 'line',\n",
    "#                                yref= 'paper', y0= 0, y1= 0.9,\n",
    "#                                xref= 'x', x0= 1.5, x1= 1.5\n",
    "#                               )\n",
    "# ])\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    legend=dict(\n",
    "        x=1,\n",
    "        y=1,\n",
    "        title=\"\",\n",
    "        # traceorder=\"reversed\",\n",
    "        #title_font_family=\"Times New Roman\",\n",
    "        font=dict(\n",
    "            family=\"Times New Roman\",\n",
    "            size=20,\n",
    "            color=\"black\"\n",
    "        ),\n",
    "        bgcolor='rgba(255, 255, 255, 0)',\n",
    "        # bordercolor=\"Black\",\n",
    "        borderwidth=0,\n",
    "        orientation='v'\n",
    "    )\n",
    ")\n",
    "\n",
    "filename= f'/storage/kiran/results/charts/overall_scores_boxplot.png'\n",
    "print(f\"Saving: {filename}\")\n",
    "fig.write_image(filename, scale=1, width=1200, height=500)\n",
    "Image(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruction Error (MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filt  = (df_metrics.compression_rate>0) & (df_metrics.compression_rate<100)\n",
    "filt &= (df_metrics.label=='average_weighted') \n",
    "#filt &= (df_metrics.input_type=='HSI') \n",
    "#filt &= (df_metrics.compression_class!='DAE') \n",
    "df =  df_metrics[filt]\n",
    "compression_classes =[\"PCA\",\"KPCA\",\"ICA\",\"AE\",\"DAE\"]\n",
    "\n",
    "df.drop(['n_components','precision','recall', 'f1','support'], axis=1, inplace=True)\n",
    "sns.set(context='paper',font=\"Times New Roman\", style=\"whitegrid\") # font_scale=2 \n",
    "\n",
    "# plt.xkcd()\n",
    "# fig, axs = plt.subplots(nrows=5, ncols=2, figsize=(16,20), sharex=True, sharey=True)\n",
    "#axs = axs.reshape(1,-1)\n",
    "ls = ['-','--','=']\n",
    "\n",
    "pbar = tqdm(enumerate(input_types))\n",
    "\n",
    "for _col, input_type in pbar:\n",
    "    for _row, compression_class in enumerate(compression_classes):\n",
    "        fig, axs = plt.subplots(nrows=1, ncols=1, figsize=(8,5), sharex=True, sharey=True)\n",
    "        axs = [axs]\n",
    "\n",
    "        for dataset in datasets:\n",
    "            pbar.set_description(f\"{dataset} {input_type} {compression_class} \")\n",
    "            chart_data = df[(df.input_type==input_type) & (df.compression_class==compression_class) & (df.dataset_name==dataset)]\n",
    "            sns.lineplot(ax=axs[0], data=chart_data, x='compression_rate', y='reconstruction_loss', label=dataset, dashes=True, markers='o', linewidth=3)\n",
    "            \n",
    "            axs[0].set_title(f\"${input_type.replace('SG','{SG}')}$\", fontdict={'fontsize': 24, 'fontfamily': 'Times New Roman'})\n",
    "            \n",
    "            # axs[0].set_ylim(ymin=-1E-12, ymax=1E-3)\n",
    "            axs[0].set_yscale(\"log\", nonposy='clip')\n",
    "            axs[0].set_ylabel(\"\")\n",
    "            # axs[0].yaxis.set_major_locator(plt.MaxNLocator(4))\n",
    "            axs[0].yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: f'{x:.1e}'))\n",
    "            axs[0].tick_params(axis='both', labelsize=28)\n",
    "            \n",
    "            axs[0].set_xlabel(\"compression rate (%)\", fontsize=24, fontfamily=\"Times New Roman\")            \n",
    "            axs[0].legend(ncol=1, loc='best', prop={'family':'Times New Roman', 'size':20}).set_visible(True)\n",
    "            axs[0].grid(True)\n",
    "            \n",
    "            \n",
    "            axs[0].set_ylabel(f\"MSE - {compression_class}\", fontsize=24, fontfamily=\"Times New Roman\")\n",
    "\n",
    "            # fig.subplots_adjust(top=0.9, left=-2, right=1, bottom=0.3)  # create some space below the plots by increasing the bottom-value\n",
    "            # axs.ravel()[0].legend(ncol=1, fontsize=26, loc='best')\n",
    "\n",
    "        \n",
    "\n",
    "        filename= f'/storage/kiran/results/charts/mse_reconstruction_{compression_class}_{input_type}.pdf'\n",
    "        print(f\"Saving: {filename}\")\n",
    "        plt.tight_layout()\n",
    "        #plt.savefig(filename, bbox='tight', dpi=300, transparent=True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variability on AE and DAE for several trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filt = (df_metrics.compression_class.isin(['AE','DAE']))\n",
    "filt &= (df_metrics.compression_rate>0) & (df_metrics.compression_rate<100)\n",
    "filt &= (df_metrics.input_type=='HSI') \n",
    "filt &= (df_metrics.label!='average_weighted') \n",
    "# filt &= (df_metrics.compression_rate.isin(range(90,100)))\n",
    "\n",
    "df = df_metrics[filt]\n",
    "df.drop(['n_components','support','precision','recall','f1','execution_times','label'], axis=1, inplace=True)\n",
    "compression_classes = sorted(df.compression_class.unique().tolist())\n",
    "categories = sorted(df_metrics.label.unique().tolist())\n",
    "display(df.groupby(['dataset_name','input_type','compression_class','compression_rate']).min())\n",
    "\n",
    "fig = px.box(data_frame=df, \n",
    "             x='dataset_name', \n",
    "             y='reconstruction_loss', \n",
    "             color='compression_class',              \n",
    "             # facet_col='com', \n",
    "             # facet_row='input_type',         \n",
    "             category_orders={'dataset_name':['Suburban','Urban','Forest'],\n",
    "                              \"compression_class\": [\"RGB\",\"PCA\",\"ICA\",\"KPCA\",\"AE\",\"DAE\"]\n",
    "                             },\n",
    "             template='plotly_white',\n",
    "             orientation='v',\n",
    "            )\n",
    "\n",
    "fig.for_each_annotation(lambda a: a.update(text=a.text.replace(\"input_type=\", \"\")))\n",
    "fig.for_each_annotation(lambda a: a.update(text=a.text.replace(\"label=\", \"\")))\n",
    "fig.for_each_annotation(lambda a: a.update(text=a.text.replace(\"compression_class=\", \"\")))\n",
    "fig.for_each_annotation(lambda a: a.update(text=a.text.replace(\"dataset_name=\", \"\")))\n",
    "fig.update_layout(legend_title=\"\",font=dict(size=24, color=\"Black\"))\n",
    "fig.layout.xaxis.title.text = \"\" # fig.layout.xaxis2.title.text = fig.layout.xaxis3.title.text = \"\"\n",
    "fig.layout.yaxis.title.text  = \"mse\"\n",
    "fig.update_layout(legend_title=\"\", font=dict(size=24, color=\"Black\", family='Times New Roman'))\n",
    "fig.update_yaxes(nticks=6, title_standoff=0, title_font=dict(size=24, family='Times New Roman'))\n",
    "fig.update_xaxes(nticks=10, title_standoff=0, title_font=dict(size=24, family='Times New Roman'))\n",
    "#fig.layout.update(showlegend=False)\n",
    "\n",
    "fig.update_layout(\n",
    "    legend=dict(\n",
    "        x=0,\n",
    "        y=1,\n",
    "        # traceorder=\"reversed\",\n",
    "        title_font_family=\"Times New Roman\",\n",
    "        font=dict(\n",
    "            family=\"Times New Roman\",\n",
    "            size=18,\n",
    "            color=\"black\"\n",
    "        ),\n",
    "        bgcolor='rgba(255, 255, 255, 0)',\n",
    "        # bordercolor=\"Black\",\n",
    "        borderwidth=0,\n",
    "        orientation='v'\n",
    "    )\n",
    ")\n",
    "\n",
    "# fig.for_each_trace(lambda t: t.update(name=t.name.replace(\"=\", \"\")))\n",
    "# fig.show()\n",
    "\n",
    "filename= f'/storage/kiran/results/charts/AE_DAE_variability.png'\n",
    "print(f\"Saving: {filename}\")\n",
    "fig.write_image(filename, scale=1.5, width=800, height=400)\n",
    "Image(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision x Compression Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filt = (df_metrics.compression_rate>0) & (df_metrics.compression_rate<100)\n",
    "filt &= (df_metrics.label!='average_weighted') \n",
    "#filt &= (df_metrics.compression_class!='DAE')\n",
    "df = df_metrics[filt]\n",
    "\n",
    "compression_classes = [\"PCA\",\"KPCA\",\"ICA\",\"AE\",\"DAE\"]\n",
    "categories = sorted(df_metrics.label.unique().tolist())\n",
    "df.drop(['n_components','support'], axis=1, inplace=True)\n",
    "\n",
    "input_types = ['HSI']\n",
    "for row, input_type in enumerate(input_types):\n",
    "    sns.set(context='paper',font=\"Times New Roman\", style=\"whitegrid\") # font_scale=2    \n",
    "    # plt.xkcd()\n",
    "    fig, axs = plt.subplots(nrows=5, ncols=3, figsize=(15,15), sharex=True, sharey=True)\n",
    "\n",
    "    for col, dataset in tqdm( enumerate(datasets)):\n",
    "        for row, compression_class in enumerate(compression_classes):\n",
    "            line_styles=['-','--','-.',':'][::-1]            \n",
    "            for curve, category in enumerate(categories):\n",
    "                \n",
    "                chart_data = df[ (df.dataset_name==dataset) & (df.compression_class==compression_class) & (df.label==category) & (df.input_type==input_type)]\n",
    "                \n",
    "                chart_data = chart_data.groupby(['dataset_name','input_type','compression_class','compression_rate'])['f1'].max().reset_index()                \n",
    "                chart_data = chart_data.sort_values(['compression_rate'])\n",
    "                \n",
    "                # display(chart_data)\n",
    "                if len(chart_data)==0:\n",
    "                    continue            \n",
    "\n",
    "                sns.lineplot(ax=axs[row,col], data=chart_data, x='compression_rate', y='f1', label=category, linewidth=2)\n",
    "                axs[row,col].lines[-1].set_linestyle(line_styles.pop())\n",
    "                \n",
    "                \n",
    "             \n",
    "                axs[row,col].legend(ncol=2, prop={'size':16}, framealpha=1).get_frame().set_facecolor('white')\n",
    "                axs[row,col].get_legend().set_visible(False)\n",
    "                \n",
    "                axs[row,col].set_title(f\"{dataset}, {compression_class}\", fontsize=24, fontfamily=\"Times New Roman\")\n",
    "\n",
    "        axs[row,col].set_ylabel('f1 score', fontsize=24, fontfamily=\"Times New Roman\")\n",
    "        axs[0,col].get_legend().set_visible(True)\n",
    "\n",
    "        \n",
    "    for ax in axs.ravel():\n",
    "        ax.grid(\"on\")\n",
    "        ax.tick_params(axis='both', labelsize=24)\n",
    "        ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: f'{x:.2f}'))\n",
    "        ax.set_xlabel(\"compression rate (%)\", fontsize=24, fontfamily=\"Times New Roman\")\n",
    "        ax.set_ylim(ymin=0.8, ymax=1)\n",
    "        ax.set_xlim(xmin=0, xmax=99)\n",
    "        ax.set_ylabel(\"f1 score\", fontsize=24, fontfamily=\"Times New Roman\" )\n",
    "        \n",
    "        \n",
    "    fig.subplots_adjust(top=0.9, left=-1, right=1, bottom=0.30)  # create some space below the plots by increasing the bottom-value\n",
    "    plt.tight_layout()\n",
    "    filename= f'/storage/kiran/results/charts/f1_score_curves_{input_type}.png'\n",
    "    print(f\"Saving: {filename}\")\n",
    "    plt.savefig(filename, bbox='tight', dpi=300, transparent=True) \n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrices for compressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['Forest','Suburban','Urban']\n",
    "compression_classes = [\"PCA\",\"KPCA\",\"ICA\",\"AE\",\"DAE\"]\n",
    "compression_rates = [0, 10, 50, 90]\n",
    "input_type = ['HSI', 'HSI_SG']\n",
    "\n",
    "items = product(datasets, input_type, compression_classes,compression_rates)\n",
    "\n",
    "for dataset, input_type, compression_class, compression_rate in tqdm(items):\n",
    "    # print(dataset, compression_class, compression_rate)\n",
    "    confusion_matrix = confusion_matrices.get((dataset, input_type, compression_class, compression_rate), None)\n",
    "    if confusion_matrix is None:\n",
    "        print(f\"Confusion Matrix not found: {(dataset, input_type, compression_class, compression_rate)}\")\n",
    "        continue\n",
    "    # display(confusion_matrix) \n",
    "    confusion_matrix.columns = [f\"{c[0]}\" for c in confusion_matrix.columns]\n",
    "    confusion_matrix.index = [f\"{c[0]}\" for c in confusion_matrix.index]\n",
    "\n",
    "    \n",
    "    sns.set(style=\"whitegrid\", font_scale=1.3,  context=\"paper\")\n",
    "    size=4\n",
    "    if len(confusion_matrix)>2:\n",
    "        size = 4\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(size,size))\n",
    "    sns.heatmap(data=confusion_matrix, \n",
    "                annot=True, \n",
    "                cmap='Pastel2_r', \n",
    "                linewidths=0.1, \n",
    "                linecolor='white', \n",
    "                cbar=False, \n",
    "                fmt='.3f', \n",
    "                ax=ax, \n",
    "                annot_kws={'size':14, 'weight':'medium'}\n",
    "               )\n",
    "    \n",
    "    plt.title(f\"{dataset}, {input_type}\", fontsize=18)\n",
    "    plt.tight_layout()\n",
    "    filename= f'/storage/kiran/results/charts/confusion_matrix_{dataset}_{compression_class}_{compression_rate}.png'\n",
    "    print(f\"Saving: {filename}\")\n",
    "    plt.savefig(filename, bbox='tight', dpi=300, transparent=True)\n",
    "    ax.tick_params(axis='x', labelsize=20, labelrotation=0)\n",
    "    ax.tick_params(axis='y', labelsize=20, labelrotation=0)\n",
    "    # plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrices for RGB, HSI, HSI_SG (non-compressed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasets = ['Forest','Suburban','Urban']\n",
    "compression_classes = ['NA']\n",
    "compression_rates = [0]\n",
    "#input_type = ['RGB','HSI', 'HSI_SG']\n",
    "input_type = ['RGB','HSI']\n",
    "\n",
    "items = product(datasets, input_type, compression_classes,compression_rates)\n",
    "\n",
    "for dataset, input_type, compression_class, compression_rate in tqdm(items):\n",
    "    # print(dataset, compression_class, compression_rate)\n",
    "        \n",
    "    confusion_matrix = confusion_matrices.get((dataset, input_type, compression_class, compression_rate), None)\n",
    "    if confusion_matrix is None:\n",
    "        print(f\"Confusion Matrix not found: {(dataset, input_type, compression_class, compression_rate)}\")\n",
    "        continue\n",
    "    display(confusion_matrix) \n",
    "    confusion_matrix.columns = [f\"{c[0]}\" for c in confusion_matrix.columns]\n",
    "    confusion_matrix.index = [f\"{c[0]}\" for c in confusion_matrix.index]\n",
    "    \n",
    "    sns.set(style=\"whitegrid\", font_scale=1.6,  context=\"paper\",font=\"Times New Roman\")\n",
    "    size=4\n",
    "    if len(confusion_matrix)>2:\n",
    "        size = 4\n",
    "    fig, ax = plt.subplots(figsize=(size,size))\n",
    "    \n",
    "    sns.heatmap(data=confusion_matrix, annot=True, cmap='Pastel2_r', linewidths=0.1, linecolor='white', cbar=False, fmt='.3f', ax=ax, annot_kws={'size':20, 'weight':'medium'})\n",
    "    plt.title(f\"{dataset}, {input_type}\", fontsize=18, fontfamily=\"Times New Roman\")\n",
    "    plt.tight_layout()\n",
    "    ax.tick_params(axis='x', labelsize=20, labelrotation=0)\n",
    "    ax.tick_params(axis='y', labelsize=20, labelrotation=0)\n",
    "\n",
    "    filename= f'/storage/kiran/results/charts/confusion_matrix_baseline_{dataset}_{input_type}.png'\n",
    "    print(f\"Saving: {filename}\")\n",
    "    plt.savefig(filename, bbox='tight', dpi=300, transparent=True)    \n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heatmap (consolidated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df_metrics.drop(['reconstruction_loss', 'support', 'n_components'], axis=1)\n",
    "filt  = (df.compression_rate>0) & (df.compression_rate<100)\n",
    "filt &= (df.label=='average_weighted')\n",
    "# filt &= (df.input_type=='HSI')\n",
    "df = df[filt]\n",
    "df.rename({'fbeta_score':'f1'}, inplace=1, axis=1)\n",
    "\n",
    "\n",
    "for i, dataset_name in enumerate(datasets):\n",
    "    for input_type in input_types:\n",
    "        sns.set(style='whitegrid', font_scale=1.6)\n",
    "        #plt.xkcd(False)\n",
    "        fig, axs = plt.subplots(nrows=len(datasets), ncols=1, figsize=(16,10), sharex=True, sharey=False)\n",
    "\n",
    "        # [left, bottom, width, height] where all quantities are in fractions of figure width and height\n",
    "        # cbar_ax = fig.add_axes([.91, .3, .03, .4])\n",
    "        cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])\n",
    "\n",
    "        for i, metric in enumerate(['precision', 'recall','f1']):\n",
    "            \n",
    "            data = df[(df.dataset_name==dataset_name) & (df.input_type==input_type)]        \n",
    "            data = data.groupby(['dataset_name','input_type','compression_class','compression_rate','label']).agg({'precision':'max', 'recall':'max', 'f1':'max'}).reset_index()            \n",
    "            data = pd.pivot_table(data, index='compression_rate', columns='compression_class', values=metric)\n",
    "            data = data[[\"PCA\",\"KPCA\",\"ICA\",\"AE\",\"DAE\"]]\n",
    "            data = data.T\n",
    "            data.columns = np.around(data.columns.ravel()).astype(int)            \n",
    "\n",
    "            sns.heatmap(data=data, ax=axs[i], vmin=0.90, vmax=1, cbar_ax=(None if i else cbar_ax), cbar=(i==0), linewidths=0.1, linecolor='lightgray', cmap='jet_r')        \n",
    "            axs[i].set_ylabel(metric, fontsize=26)\n",
    "\n",
    "            axs[i].tick_params(axis='x', labelrotation=0, labelsize=20, which='major')\n",
    "            axs[i].tick_params(axis='y', labelrotation=0, labelsize=20, which='major')\n",
    "            axs[-1].set_xlabel(\"compression rate (%)\", fontsize=24)\n",
    "            \n",
    "            \n",
    "            \n",
    "            _ = [a.set_text('') for idx, a in enumerate(axs[i].get_xticklabels()) if ((idx*2)%3!=0)]\n",
    "            xticklabels = (list(axs[i].get_xticklabels()))\n",
    "            axs[i].set_xticklabels(xticklabels)\n",
    "            \n",
    "            \n",
    "            \n",
    "        # plt.tight_layout()\n",
    "        plt.suptitle(f\"{dataset_name}, {input_type}\", y=0.95, fontsize=24)\n",
    "        filename= f'/storage/kiran/results/charts/heatmap_{dataset_name}_{input_type}.png'\n",
    "        print(f\"Saving: {filename}\")\n",
    "        plt.savefig(filename, bbox='tight', dpi=300, transparent=True)\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filt  = (df_metrics.compression_rate>=95) & (df_metrics.compression_rate<99)\n",
    "cr = 95\n",
    "filt  = ((df_metrics.compression_rate==cr) | (df_metrics.input_type=='RGB'))\n",
    "filt &= (df_metrics.label!='average_weighted') \n",
    "df =  df_metrics[filt]\n",
    "df = df[['dataset_name',\n",
    "         'label',\n",
    "         'input_type',\n",
    "         'compression_class',\n",
    "         'compression_rate',\n",
    "         #'n_components',         \n",
    "         'precision',\n",
    "         'recall',\n",
    "         'f1',\n",
    "         'reconstruction_loss'\n",
    "        ]]\n",
    "df['f1-score'] = df.f1\n",
    "df.loc[df.input_type=='RGB', 'compression_class'] = 'RGB'\n",
    "df.loc[df.input_type=='RGB', 'compression_rate'] = cr\n",
    "df.loc[df.input_type=='RGB', 'input_type'] = 'HSI'\n",
    "\n",
    "# ----------------------------------------------------\n",
    "\n",
    "def color_max(x):  \n",
    "    c1 = 'color: green; font-weight: bold'\n",
    "    c2 = 'color: red; font-style: italic'\n",
    "    c3 = 'color: gray'    \n",
    "    ret = pd.DataFrame(c3, columns=x.columns, index=x.index)\n",
    "    \n",
    "    m = x.groupby(['label']).agg({'precision':'idxmax','recall':'idxmax','f1-score':'idxmax'})    \n",
    "    ret.loc[m['precision'],'precision'] = c1\n",
    "    ret.loc[m['recall'],'recall'] = c1\n",
    "    ret.loc[m['f1-score'],'f1-score'] = c1    \n",
    "    \n",
    "    m = x.groupby(['label']).agg({'precision':'idxmin','recall':'idxmin','f1-score':'idxmin'})\n",
    "    ret.loc[m['precision'],'precision'] = c2\n",
    "    ret.loc[m['recall'],'recall'] = c2\n",
    "    ret.loc[m['f1-score'],'f1-score'] = c2\n",
    "    \n",
    "    return ret\n",
    "    \n",
    "for t, input_type in enumerate(['HSI']):\n",
    "    table = []\n",
    "    for i, dataset_name in enumerate(datasets):\n",
    "        data = df[(df.dataset_name==dataset_name) & (df.input_type==input_type)]\n",
    "\n",
    "        # Max here is only for AE, DAE, because of multiple runs. Other should have only one valued for cr=95%.\n",
    "        table = data.groupby(['dataset_name','input_type','label','compression_class']).agg({'precision':'max','recall':'max','f1-score':'max'})        \n",
    "        table.rename({'precision':'precision',\n",
    "                      'recall':'recall',\n",
    "                      'f1-score':'f1-score'\n",
    "                     },inplace=True, axis=1)\n",
    "\n",
    "        table = table.reset_index().drop(['dataset_name','input_type'], axis=1)\n",
    "        table.rename({'compression_class': 'compression'}, inplace=True, axis=1)\n",
    "        \n",
    "        sorter = [\"RGB\",\"PCA\",\"KPCA\",\"ICA\",\"AE\",\"DAE\"]\n",
    "        sorterIndex = dict(zip(sorter, range(len(sorter))))\n",
    "        # the dataframe numerically\n",
    "        table['order'] = table.compression.map(sorterIndex)\n",
    "        table = table.sort_values(['label','order'])\n",
    "        table.set_index(['label','compression'], inplace=True)        \n",
    "        del table['order']\n",
    "        styled_table = table.style.apply(color_max, axis=None)            \n",
    "        display(styled_table)\n",
    "        \n",
    "        \n",
    "        filename= f'/storage/kiran/results/charts/top_classification_scores_{dataset_name}_{input_type}'\n",
    "        hl = \"\\(high compression rates\\)\"\n",
    "        label = f\"table:top_classification_scores_{dataset_name}_{input_type}\"\n",
    "        _c = input_type.replace(\"HSI_SG\", \"$HSI_{SG}$\")\n",
    "        caption = f\"Top classification scores {dataset_name}, {_c}, compression rate={cr}\\%\"    \n",
    "        \n",
    "        print(f\"Saving: {filename}\")\n",
    "        dfi.export(styled_table, f\"{filename}.png\", fontsize=30)\n",
    "        display(Image(f\"{filename}.png\"))        \n",
    "        \n",
    "        table.to_excel(f\"{filename}.xls\", float_format=\"%.4f\")\n",
    "        table_latex = table.to_latex(buf=None,\n",
    "                       caption=caption,\n",
    "                       label=label,\n",
    "                       header = True,\n",
    "                       multicolumn=True,\n",
    "                       multirow=True,\n",
    "                       bold_rows=True,\n",
    "                       index=True,\n",
    "                       float_format=\"%.3f\"\n",
    "                      )\n",
    "        \n",
    "        table_latex = table_latex.replace('begin{table}','begin{table}[H]')\n",
    "        table_latex = table_latex.replace('centering','centering \\\\footnotesize')                          \n",
    "        display(Latex(table_latex))        \n",
    "        open(f\"{filename}.tex\",'w+').write(table_latex)\n",
    "        display(Latex(open(f\"{filename}.tex\").read()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision vs. Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt  = (df_metrics.compression_rate>0) & (df_metrics.compression_rate<100)\n",
    "#filt &= (df_metrics.input_type=='HSI_SG') \n",
    "filt &= (df_metrics.label!='average_weighted') \n",
    "df =  df_metrics[filt]\n",
    "df.drop(['f1','support','reconstruction_loss','execution_times'], inplace=True, axis=1)\n",
    "# df.compression_rate = 1 - (df.compression_rate / 100)\n",
    "# df.sort_values('compression_rate', ascending=False, inplace=True)\n",
    "display(df)\n",
    "\n",
    "df = df.groupby(['dataset_name','input_type','compression_class','label','compression_rate']).agg({'precision':'max', 'recall':'max'}).reset_index()\n",
    "# df.rename({'compression_rate': 'compression (%)'},axis=1, inplace=True)\n",
    "\n",
    "# import retrying\n",
    "# unwrapped = plotly.io._orca.request_image_with_retrying.__wrapped__\n",
    "# wrapped = retrying.retry(wait_random_min=1000)(unwrapped)\n",
    "# plotly.io._orca.request_image_with_retrying = wrapped\n",
    "\n",
    "\n",
    "fig = px.scatter(df, \n",
    "                 y=\"precision\", \n",
    "                 x=\"recall\", \n",
    "                 color=\"compression_rate\",                 \n",
    "                 # symbol='compression_class',                 \n",
    "                 facet_col=\"label\", \n",
    "                 facet_col_wrap=5,\n",
    "                 facet_row='compression_class',\n",
    "                 # size='compression_rate',\n",
    "                 category_orders={\"compression_class\": [\"PCA\",\"KPCA\",\"ICA\",\"AE\", \"DAE\"], \n",
    "                                  \"dataset_name\": [\"Suburban\", \"Urban\",\"Forest\"], \n",
    "                                  \"label\": [\"Asphalt, Rooftop, Grass\"]\n",
    "                                 },\n",
    "                 #labels={'dataset_name': '', 'compression_class':''},\n",
    "                 # template=\"plotly\",                                 \n",
    "                 range_x=[0, 1],\n",
    "                 range_y=[0, 1],                 \n",
    "                 size_max=5,\n",
    "                 opacity=0.8,\n",
    "                 color_continuous_scale='Bluered_r',\n",
    "                 #color_continuous_scale=[\"red\", \"blue\"]\n",
    "                )\n",
    "\n",
    "fig.for_each_annotation(lambda a: a.update(text=a.text.replace(\"label=\", \"\")))\n",
    "fig.for_each_annotation(lambda a: a.update(text=a.text.replace(\"compression_class=\", \"\")))\n",
    "fig.for_each_trace(lambda t: t.update(name=t.name.replace(\"=\", \"\")))\n",
    "fig.update_layout(legend_title_text=\"\", legend_title_font=dict(size=1), font=dict(size=18, color=\"Black\", family='Times New Roman'))\n",
    "fig.update_xaxes(nticks=3, title_standoff=0, title_font=dict(size=14, family='Times New Roman'))\n",
    "fig.update_yaxes(nticks=3, title_standoff=0, title_font=dict(size=14, family='Times New Roman'), tickfont=dict(size=18))\n",
    "\n",
    "fig.update_layout(coloraxis_colorbar=dict(title=\"compression (%)\", titlefont=dict(size=14)))\n",
    "\n",
    "\n",
    "filename= f'/storage/kiran/results/charts/precision_vs_recall.png'\n",
    "print(f\"Saving: {filename}\")\n",
    "fig.write_image(filename, scale=1, width=1200, height=800)\n",
    "Image(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
